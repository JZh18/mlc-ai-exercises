{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.5 Exercise for TensorIR",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrtm1H2ERXt1",
        "outputId": "27314764-6225-4627-90c2-9ebb915e6287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Requirement already satisfied: mlc-ai-nightly in /usr/local/lib/python3.7/dist-packages (0.9.dev1664+g1f3985de0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.4.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.4.1)\n",
            "Requirement already satisfied: synr==0.6.0 in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.21.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (21.4.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T"
      ],
      "metadata": {
        "id": "vT5O59acRn5S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5.1.1. Example: Element-wise Add"
      ],
      "metadata": {
        "id": "LlYhvFvQ2FjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(16, 0, -1).reshape(4, 4)"
      ],
      "metadata": {
        "id": "-H3sGOn8RtNz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EciuJ1r4RxHI",
        "outputId": "8edfaad3-4765-4a63-f4e1-f3fa7e6b7535"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy version\n",
        "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[i, j]\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FpTGKpZR4Bt",
        "outputId": "a1b7dff3-bee1-4cc0-c600-67612d0130c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorIR version\n",
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4, 4), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "wdEmXzF-R-be"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5.1.2. Exercise 1: Broadcast Add"
      ],
      "metadata": {
        "id": "P7RYGDcG2ld6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)"
      ],
      "metadata": {
        "id": "DdKkQ5Y_nSoN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e71SMSpnbV2",
        "outputId": "06684550-79d6-4ecf-9e2a-2a080585a8ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4, ), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "      \n",
        "        \n",
        "  \n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "-VQ2Q9R7ncg1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5.1.3. Exercise 2: 2D Convolution\n"
      ],
      "metadata": {
        "id": "EinOqMe52tfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1 # 6, 6\n",
        "data = np.arange(N*CI*H*W).reshape(N, CI, H, W) # 1,1,8,8\n",
        "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K) # 2,1,3,3"
      ],
      "metadata": {
        "id": "HChru5fkneL4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "import torch\n",
        "\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUo9eh7WtgGX",
        "outputId": "fa45017c-5ff8-4326-e47b-26e050e57418"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 474,  510,  546,  582,  618,  654],\n",
              "         [ 762,  798,  834,  870,  906,  942],\n",
              "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
              "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
              "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
              "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
              "\n",
              "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
              "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
              "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
              "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
              "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
              "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(A: T.Buffer[(1, 1, 8, 8), \"int64\"], # 1,1,8,8\n",
        "          B: T.Buffer[(2, 1, 3, 3), \"int64\"], # 2,1,3,3\n",
        "          C: T.Buffer[(1, 2, 6, 6), \"int64\"]): # 1,2,6,6\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    for n, c, h, w, i, k1, k2 in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
        "      with T.block(\"C\"):\n",
        "        vn = T.axis.spatial(1, n)\n",
        "        vc = T.axis.spatial(2, c)\n",
        "        vh = T.axis.spatial(6, h)\n",
        "        vw = T.axis.spatial(6, w)\n",
        "        vi = T.axis.spatial(1, i)\n",
        "        vk1 = T.axis.reduce(3, k1)\n",
        "        vk2 = T.axis.reduce(3, k2)\n",
        "        with T.init():\n",
        "          C[vn, vc, vh, vw] = T.int64(0)\n",
        "        C[vn, vc, vh, vw] = C[vn, vc, vh, vw] + A[vn, vi, vh + vk1, vw + vk2] * B[vc, vi, vk1, vk2]\n",
        "\n",
        "\n",
        "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "data_tvm = tvm.nd.array(data)\n",
        "weight_tvm = tvm.nd.array(weight)\n",
        "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "tg9mMWS1thqf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5.2.2. Exercise 3: Transform a batch matmul program"
      ],
      "metadata": {
        "id": "Lq9TfOHO21Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
        "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                for k in range(128):\n",
        "                    if k == 0:\n",
        "                        Y[n, i, j] = 0\n",
        "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "    for n in range(16):\n",
        "        for i in range(128):\n",
        "            for j in range(128):\n",
        "                C[n, i, j] = max(Y[n, i, j], 0)"
      ],
      "metadata": {
        "id": "J1PebIPPwm6f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(16*128*128, dtype=np.float32).reshape(16, 128, 128)\n",
        "b = np.arange(16*128*128, 0, -1, dtype=np.float32).reshape(16, 128, 128)\n",
        "expected_c = np.empty((16, 128, 128), dtype=np.float32)\n",
        "lnumpy_mm_relu_v2(a, b, expected_c)"
      ],
      "metadata": {
        "id": "qrxd_F5D6Wes"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRule:\n",
        "  @T.prim_func\n",
        "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], \n",
        "               B: T.Buffer[(16, 128, 128), \"float32\"], \n",
        "               C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
        "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "    Y = T.alloc_buffer((16, 128, 128), dtype=\"float32\")\n",
        "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
        "      with T.block(\"Y\"):\n",
        "        vn = T.axis.spatial(16, n)\n",
        "        vi = T.axis.spatial(128, i)\n",
        "        vj = T.axis.spatial(128, j)\n",
        "        vk = T.axis.reduce(128, k)\n",
        "        with T.init():\n",
        "          Y[vn, vi, vj] = T.float32(0)\n",
        "        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
        "    for n, i, j in T.grid(16, 128, 128):\n",
        "      with T.block(\"C\"):\n",
        "        vn = T.axis.spatial(16, n)\n",
        "        vi = T.axis.spatial(128, i)\n",
        "        vj = T.axis.spatial(128, j)\n",
        "        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
        "\n",
        "    \n",
        "\n",
        "sch = tvm.tir.Schedule(MyBmmRule)\n",
        "print(sch.mod.script())\n",
        "# Also please validate your result\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((16, 128, 128), dtype=np.float32))\n",
        "rt_lib = tvm.build(MyBmmRule, target=\"llvm\")\n",
        "rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), expected_c, rtol=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KseFejqAz-YV",
        "outputId": "9f3dbbdc-f184-4851-fc5c-b6b631b2e37d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n, i, j, k in tir.grid(16, 128, 128, 128):\n",
            "            with tir.block(\"Y\"):\n",
            "                vn, vi, vj, vk = tir.axis.remap(\"SSSR\", [n, i, j, k])\n",
            "                tir.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
            "                tir.writes(Y[vn, vi, vj])\n",
            "                with tir.init():\n",
            "                    Y[vn, vi, vj] = tir.float32(0)\n",
            "                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "        for n, i, j in tir.grid(16, 128, 128):\n",
            "            with tir.block(\"C\"):\n",
            "                vn, vi, vj = tir.axis.remap(\"SSS\", [n, i, j])\n",
            "                tir.reads(Y[vn, vi, vj])\n",
            "                tir.writes(C[vn, vi, vj])\n",
            "                C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class TargetModule:\n",
        "    @T.prim_func\n",
        "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
        "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "        for i0 in T.parallel(16):\n",
        "            for i1, i2_0 in T.grid(128, 16):\n",
        "                for ax0_init in T.vectorized(8):\n",
        "                    with T.block(\"Y_init\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
        "                        Y[n, i, j] = T.float32(0)\n",
        "                for ax1_0 in T.serial(32):\n",
        "                    for ax1_1 in T.unroll(4):\n",
        "                        for ax0 in T.serial(8):\n",
        "                            with T.block(\"Y_update\"):\n",
        "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
        "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
        "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "                for i2_1 in T.vectorized(8):\n",
        "                    with T.block(\"C\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
        "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
      ],
      "metadata": {
        "id": "txcAQIZL-m7C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRule)\n",
        "# TODO: transformations\n",
        "# Hints: you can use\n",
        "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
        "# or `print(sch.mod.script())`\n",
        "# to show the current program at any time during the transformation.\n",
        "\n",
        "# Step 1. Get blocks\n",
        "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "\n",
        "\n",
        "# Step 2. Get loops\n",
        "b, i, j, k = sch.get_loops(Y)\n",
        "sch.parallel(b)\n",
        "\n",
        "# Step 3. Organize the loops\n",
        "j0, j1 = sch.split(j, factors=[None, 8])\n",
        "sch.reorder(j0,k, j1)\n",
        "block_C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
        "sch.reverse_compute_at(block_C, j0)\n",
        "\n",
        "# Step 4. decompose reduction\n",
        "Y_init = sch.decompose_reduction(Y, k)\n",
        "n, i, j_0, j_1_init = sch.get_loops(Y_init)\n",
        "_, _, _, ax0 = sch.get_loops(block_C)\n",
        "Y_update_block = sch.get_block(\"Y_update\", func_name=\"bmm_relu\")\n",
        "_, _, _, k, j_1 = sch.get_loops(Y_update_block)\n",
        "k0, k1 = sch.split(k, factors=[32, 4])\n",
        "\n",
        "\n",
        "# # Step 5. vectorize / parallel / unroll\n",
        "sch.vectorize(j_1_init)\n",
        "sch.vectorize(ax0)\n",
        "sch.unroll(k1)\n",
        "\n",
        "print(sch.mod.script())"
      ],
      "metadata": {
        "id": "cqGEAytv0AAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107893be-cc0a-43d3-eb26-5dc3bdc2d033"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tvm.script.ir_module\n",
            "class Module:\n",
            "    @tir.prim_func\n",
            "    def bmm_relu(A: tir.Buffer[(16, 128, 128), \"float32\"], B: tir.Buffer[(16, 128, 128), \"float32\"], C: tir.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "        # function attr dict\n",
            "        tir.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
            "        # body\n",
            "        # with tir.block(\"root\")\n",
            "        Y = tir.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
            "        for n in tir.parallel(16):\n",
            "            for i, j_0 in tir.grid(128, 16):\n",
            "                for j_1_init in tir.vectorized(8):\n",
            "                    with tir.block(\"Y_init\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 8 + j_1_init)\n",
            "                        tir.reads()\n",
            "                        tir.writes(Y[vn, vi, vj])\n",
            "                        Y[vn, vi, vj] = tir.float32(0)\n",
            "                for k_0 in tir.serial(32):\n",
            "                    for k_1 in tir.unroll(4):\n",
            "                        for j_1 in tir.serial(8):\n",
            "                            with tir.block(\"Y_update\"):\n",
            "                                vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                                vj = tir.axis.spatial(128, j_0 * 8 + j_1)\n",
            "                                vk = tir.axis.reduce(128, k_0 * 4 + k_1)\n",
            "                                tir.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
            "                                tir.writes(Y[vn, vi, vj])\n",
            "                                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
            "                for ax0 in tir.vectorized(8):\n",
            "                    with tir.block(\"C\"):\n",
            "                        vn, vi = tir.axis.remap(\"SS\", [n, i])\n",
            "                        vj = tir.axis.spatial(128, j_0 * 8 + ax0)\n",
            "                        tir.reads(Y[vn, vi, vj])\n",
            "                        tir.writes(C[vn, vi, vj])\n",
            "                        C[vn, vi, vj] = tir.max(Y[vn, vi, vj], tir.float32(0))\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
        "print(\"Pass\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_DkYsgN1yT0",
        "outputId": "22ab2d75-15cb-4216-b445-13ab30ea384c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before_rt_lib = tvm.build(MyBmmRule, target=\"llvm\")\n",
        "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"Before transformation:\")\n",
        "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
        "\n",
        "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"After transformation:\")\n",
        "print(f_timer(a_tvm, b_tvm, c_tvm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UIi7FCYznFt",
        "outputId": "34c61be9-9d2c-4948-f78d-fef9c91fe94d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  50.1435      50.1435      50.1435      50.1435       0.0000   \n",
            "               \n",
            "After transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  14.4953      14.4953      14.4953      14.4953       0.0000   \n",
            "               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BS4RZ0Oq1He1"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}